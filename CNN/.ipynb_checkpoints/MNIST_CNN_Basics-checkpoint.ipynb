{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99963980-d0d0-4246-9093-b1f356027989",
   "metadata": {},
   "source": [
    "# Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a7faa6-9189-4f91-9452-2e43a0d86776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f905ad-6b5b-4f43-a78e-6400da53ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2210e6-f6bb-4d7a-b2a6-870cc26ea9b0",
   "metadata": {},
   "source": [
    "### Convering MNIST Images to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b88181-866e-47ea-a340-153c3e37dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d17a36f6-20cd-4f46-9eef-423af66c0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root = './data', train = True, download= True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f9e6779-6e54-4f41-8206-5932d9ecb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(root = './data', train = False, download= True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4451671f-d7c4-492b-a84a-1569f8248f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff4c1c7-78d8-47ab-9b15-4f8d66b7705e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 indicates grayscale, 3 would be RGB\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a967f0-155b-4ca5-b969-47ee99eb771c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22226967-60f7-4734-ab08-9bedfecea514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.reshape((28,28)), cmap='gist_yarg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bb80f-df8e-456b-8580-89fef0e8f826",
   "metadata": {},
   "source": [
    "### Some ideas about image processing and computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25cc0127-c1b6-47f5-9c7e-6afcc1d49166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters are image kernels - a small matrix of weights/values applied to an entire image\n",
    "# We \"stride\" this filter across the entire image\n",
    "# Visualization https://setosa.io/ev/image-kernels\n",
    "# NNs will change the wts for this filters to do apt feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9827e6-0300-4f79-a6ee-5ab3c01b294d",
   "metadata": {},
   "source": [
    "### Rather than loading all of the dataset at once, we will load a subset/batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5d71248-d044-4a15-905d-2444bc8eddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls randomization\n",
    "torch.manual_seed(101)\n",
    "# shuffling is important in case the data is ordered by class\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08064f12-dbb9-4168-84c5-03ecef6ff440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Grayscale, 6 - Number of filters of feature maps we want to have, 3*3 - kernel size, 1 is the stride, no padding needed as all images are centred and we can afford to lose edge data\n",
    "# conv1 = nn.Conv2d(1,6,3,1)\n",
    "# pooling layer and then the next one\n",
    "# conv2 = nn.Conv2d(6,16,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19fb79a0-61dc-446f-b117-fd61d1e0cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,3,1)\n",
    "        self.conv2 = nn.Conv2d(6,16,3,1)\n",
    "        self.fc1 = nn.Linear(5*5*16, 120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, X): \n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X,2,2)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X,2,2)\n",
    "        X = X.view(-1,16*5*5)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return F.log_softmax(X, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb3a9511-5810-48c4-bb1b-5e7958d76650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = ConvolutionalNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d55c7d5-e7f9-42c4-ad38-9ca31f12d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "6\n",
      "864\n",
      "16\n",
      "48000\n",
      "120\n",
      "10080\n",
      "84\n",
      "840\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "808128bf-09a6-41d3-8707-b135e8f3f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1473522c-24e0-4c97-9cac-5734ad87324f",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5124df5d-3df3-4b8e-b1db-6e2b6a3af4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0 BATCH : 600 LOSS: 0.001461043837480247\n",
      "EPOCH : 0 BATCH : 1200 LOSS: 0.0010011005215346813\n",
      "EPOCH : 0 BATCH : 1800 LOSS: 0.0030226605013012886\n",
      "EPOCH : 0 BATCH : 2400 LOSS: 0.0006059683510102332\n",
      "EPOCH : 0 BATCH : 3000 LOSS: 0.2240818440914154\n",
      "EPOCH : 0 BATCH : 3600 LOSS: 0.02581975981593132\n",
      "EPOCH : 0 BATCH : 4200 LOSS: 0.013168220408260822\n",
      "EPOCH : 0 BATCH : 4800 LOSS: 0.0014112270437180996\n",
      "EPOCH : 0 BATCH : 5400 LOSS: 0.0004959137877449393\n",
      "EPOCH : 0 BATCH : 6000 LOSS: 9.541473991703242e-05\n",
      "EPOCH : 1 BATCH : 600 LOSS: 0.0016976980259642005\n",
      "EPOCH : 1 BATCH : 1200 LOSS: 0.0007318216958083212\n",
      "EPOCH : 1 BATCH : 1800 LOSS: 0.00021658379409927875\n",
      "EPOCH : 1 BATCH : 2400 LOSS: 0.00042896941886283457\n",
      "EPOCH : 1 BATCH : 3000 LOSS: 3.489069058559835e-05\n",
      "EPOCH : 1 BATCH : 3600 LOSS: 0.002846740186214447\n",
      "EPOCH : 1 BATCH : 4200 LOSS: 0.0007213850622065365\n",
      "EPOCH : 1 BATCH : 4800 LOSS: 0.016500163823366165\n",
      "EPOCH : 1 BATCH : 5400 LOSS: 0.00651472806930542\n",
      "EPOCH : 1 BATCH : 6000 LOSS: 0.0014665824128314853\n",
      "EPOCH : 2 BATCH : 600 LOSS: 0.0010947982082143426\n",
      "EPOCH : 2 BATCH : 1200 LOSS: 0.023347849026322365\n",
      "EPOCH : 2 BATCH : 1800 LOSS: 0.0001659602567087859\n",
      "EPOCH : 2 BATCH : 2400 LOSS: 0.000303101958706975\n",
      "EPOCH : 2 BATCH : 3000 LOSS: 0.002151777734979987\n",
      "EPOCH : 2 BATCH : 3600 LOSS: 4.3293035560054705e-05\n",
      "EPOCH : 2 BATCH : 4200 LOSS: 0.0002881975960917771\n",
      "EPOCH : 2 BATCH : 4800 LOSS: 0.00045157154090702534\n",
      "EPOCH : 2 BATCH : 5400 LOSS: 6.679914804408327e-05\n",
      "EPOCH : 2 BATCH : 6000 LOSS: 0.0017371639842167497\n",
      "EPOCH : 3 BATCH : 600 LOSS: 0.00024290705914609134\n",
      "EPOCH : 3 BATCH : 1200 LOSS: 0.008100028149783611\n",
      "EPOCH : 3 BATCH : 1800 LOSS: 0.013521768152713776\n",
      "EPOCH : 3 BATCH : 2400 LOSS: 0.00016143787070177495\n",
      "EPOCH : 3 BATCH : 3000 LOSS: 5.354122185963206e-05\n",
      "EPOCH : 3 BATCH : 3600 LOSS: 0.0029791819397360086\n",
      "EPOCH : 3 BATCH : 4200 LOSS: 7.626415754202753e-05\n",
      "EPOCH : 3 BATCH : 4800 LOSS: 3.039824605366448e-06\n",
      "EPOCH : 3 BATCH : 5400 LOSS: 9.419737762073055e-05\n",
      "EPOCH : 3 BATCH : 6000 LOSS: 0.00018721507512964308\n",
      "EPOCH : 4 BATCH : 600 LOSS: 0.0021033992525190115\n",
      "EPOCH : 4 BATCH : 1200 LOSS: 0.000425197824370116\n",
      "EPOCH : 4 BATCH : 1800 LOSS: 0.004383536987006664\n",
      "EPOCH : 4 BATCH : 2400 LOSS: 0.001652631675824523\n",
      "EPOCH : 4 BATCH : 3000 LOSS: 0.0001436646853107959\n",
      "EPOCH : 4 BATCH : 3600 LOSS: 3.7174566386966035e-05\n",
      "EPOCH : 4 BATCH : 4200 LOSS: 0.0008818249334581196\n",
      "EPOCH : 4 BATCH : 4800 LOSS: 0.03125544637441635\n",
      "EPOCH : 4 BATCH : 5400 LOSS: 0.0004148494335822761\n",
      "EPOCH : 4 BATCH : 6000 LOSS: 0.0015414069639518857\n",
      "Training took 0.48589760065078735 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "epochs = 5\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    trn_correct = 0\n",
    "    tst_correct = 0\n",
    "    for b, (x_train, y_train) in enumerate(train_loader):\n",
    "        b+=1\n",
    "        y_pred = model(x_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        predicted = torch.max(y_pred.data,1)[1]\n",
    "        batch_corr = (predicted == y_train).sum()\n",
    "        trn_correct += batch_corr\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (b%600 == 0):\n",
    "            print(f\"EPOCH : {i} BATCH : {b} LOSS: {loss.item()}\")\n",
    "    train_losses.append(loss.item())\n",
    "    train_correct.append(trn_correct)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b, (x_test, y_test) in enumerate(test_loader):\n",
    "            y_val = model(x_test)\n",
    "\n",
    "            predicted = torch.max(y_val.data,1)[1]\n",
    "            tst_correct += (predicted == y_test).sum()\n",
    "\n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss.item())\n",
    "    test_correct.append(tst_correct)\n",
    "\n",
    "        \n",
    "current_time = time.time()\n",
    "total = current_time - start_time\n",
    "print(f\"Training took {total/60} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9acb010-7a67-4e63-8ba0-dc163078ade3",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61f04ddd-d51a-4221-b1f6-8b32e90b32f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_losses)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "train_losses.detach().numpy()\n",
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20153c69-e5e4-4024-8320-045a1b72fe94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274e162-9efe-4eb3-a132-6ca2f777d466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
